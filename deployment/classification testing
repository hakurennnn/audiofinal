{"cells":[{"cell_type":"markdown","metadata":{"id":"q8T5spoaISJq"},"source":["#imports"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.models import load_model\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","\n","# Load the VGGish layer and the trained model\n","vggish_model_handle = 'https://tfhub.dev/google/vggish/1'\n","vggish_layer = hub.KerasLayer(vggish_model_handle, trainable=False)  # Set trainable to False\n","model = load_model('/content/bestbigru.keras')\n","\n","def process_audio_file(file_path):\n","    try:\n","        audio, _ = librosa.load(file_path, sr=22050)\n","        if audio.ndim > 1:\n","            audio = np.mean(audio, axis=1)  # Convert to mono if stereo\n","        if np.max(audio) < 0.01:\n","            print(f\"File {file_path} is silent or low volume, skipping.\")\n","            return None\n","        audio = librosa.util.normalize(audio)\n","        return audio\n","    except Exception as e:\n","        print(f\"Error loading file {file_path}: {e}\")\n","        return None\n","\n","def extract_vggish_features(audio_data):\n","    return vggish_layer(tf.convert_to_tensor(audio_data, dtype=tf.float32)).numpy()\n","\n","def extract_custom_features(audio_data):\n","    mfcc_features = librosa.feature.mfcc(y=audio_data, sr=22050, n_mfcc=20)\n","    mfcc_features = np.mean(mfcc_features.T, axis=0)  # Take the mean across time\n","\n","    chroma_features = librosa.feature.chroma_stft(y=audio_data, sr=22050)\n","    chroma_features = np.mean(chroma_features.T, axis=0)\n","\n","    spectral_contrast = librosa.feature.spectral_contrast(y=audio_data, sr=22050)\n","    spectral_contrast = np.mean(spectral_contrast.T, axis=0)\n","\n","    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=22050)\n","    mel_spectrogram = np.mean(mel_spectrogram.T, axis=0)\n","\n","    # Concatenate all features\n","    combined_features = np.concatenate([\n","        mfcc_features,\n","        chroma_features,\n","        spectral_contrast,\n","        mel_spectrogram,\n","    ])\n","\n","    return combined_features\n","\n","def pad_to_length(array, target_length, axis=0):\n","    current_length = array.shape[axis]\n","    if current_length < target_length:\n","        pad_width = [(0, 0)] * array.ndim\n","        pad_width[axis] = (0, target_length - current_length)\n","        array = np.pad(array, pad_width, mode='constant')\n","    elif current_length > target_length:\n","        slices = [slice(None)] * array.ndim\n","        slices[axis] = slice(0, target_length)\n","        array = array[tuple(slices)]\n","    return array\n","\n","def predict_audio(file_path):\n","    audio = process_audio_file(file_path)\n","    if audio is None:\n","        return \"Invalid audio file\"\n","\n","    max_len = 22050 * 10\n","    target_length = 14\n","\n","    segments = [audio[i * max_len:(i + 1) * max_len] for i in range(int(np.ceil(len(audio) / max_len)))]\n","    segments = [np.pad(seg, (0, max_len - len(seg)), 'constant') if len(seg) < max_len else seg for seg in segments]\n","\n","    # Extract VGGish features\n","    with ThreadPoolExecutor(max_workers=8) as executor:\n","        vggish_features = list(tqdm(executor.map(extract_vggish_features, segments), total=len(segments)))\n","\n","    vggish_features = np.array(vggish_features)\n","    if len(vggish_features.shape) == 3 and vggish_features.shape[0] == 1:\n","        vggish_features = np.squeeze(vggish_features, axis=0)\n","    vggish_features = pad_to_length(vggish_features, target_length, axis=0)\n","    print(f\"VGGish feature extraction completed. Shape: {vggish_features.shape}\")\n","\n","    # Extract custom features\n","    with ThreadPoolExecutor(max_workers=8) as executor:\n","        custom_features = list(tqdm(executor.map(extract_custom_features, segments), total=len(segments)))\n","\n","    custom_features = np.array(custom_features)\n","    if len(custom_features.shape) == 3 and custom_features.shape[0] == 1:\n","        custom_features = np.squeeze(custom_features, axis=0)\n","    custom_features_expanded = np.repeat(custom_features[:, np.newaxis, :], target_length, axis=1)\n","    custom_features_expanded = pad_to_length(custom_features_expanded, target_length, axis=1)\n","    print(f\"Custom feature extraction completed. Shape: {custom_features_expanded.shape}\")\n","\n","    # Ensure both features have the same shape for concatenation\n","    if len(vggish_features.shape) == 2:\n","        vggish_features = np.expand_dims(vggish_features, axis=0)\n","\n","    if len(custom_features_expanded.shape) == 2:\n","        custom_features_expanded = np.expand_dims(custom_features_expanded, axis=0)\n","\n","    features = np.concatenate([vggish_features, custom_features_expanded], axis=-1)\n","    print(f\"Combined feature extraction completed. Shape: {features.shape}\")\n","\n","    predictions = []\n","    for feature in features:\n","        feature = np.expand_dims(feature, axis=0)  # Add batch dimension\n","        prediction = model.predict(feature)\n","        predictions.append(prediction)\n","\n","    average_prediction = np.mean(predictions)\n","    predicted_class = 'REAL' if average_prediction > 0.5 else 'FAKE'\n","    return predicted_class\n","\n","def predict_folder(folder_path):\n","    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.wav')]\n","    predictions = {}\n","\n","    for file_path in tqdm(file_paths, desc=\"Processing files\"):\n","        predictions[file_path] = predict_audio(file_path)\n","\n","    return predictions"],"metadata":{"id":"7NW_36EtxoBj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_audio_file_path = '/content/drive/MyDrive/wav/PDFiles/datasets-lj/LJ001-0004.wav'\n","predicted_class = predict_audio(new_audio_file_path)\n","print(f\"The predicted class for the new audio file is: {predicted_class}\")"],"metadata":{"id":"CRNahtSQWbYl"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1I-UpP6PU8-48Vx73GeqYe-DvXRL8T0LQ","timestamp":1722102174256},{"file_id":"1UeGE5L2p3EXPw5zcpft2BG1r19568BTJ","timestamp":1722006979375},{"file_id":"1Mlq16dfG_gRPb6t3OQBmwIm8PE712VNS","timestamp":1721892550702},{"file_id":"180wigc0MtyzSm38zUv45w0o8dYnUB6GE","timestamp":1720370234719},{"file_id":"1Vx9HInB2vjGvBrAE2LD9rqA92v5Jb62E","timestamp":1720288526337},{"file_id":"1SRsHBM4bVi6wEg29fwUXiiZl1wxTt3mt","timestamp":1720207810358},{"file_id":"1Au2aWdQ9ZKZYfaFdi9Mks4_E0cT0Fsma","timestamp":1720176576717},{"file_id":"1JocVCOi0mWhI3t3j2zWtO-t9zrn7m5kJ","timestamp":1719335189030},{"file_id":"1QeV-7BvlFtUsMJIx6w9Teed-UhQ-xTL0","timestamp":1719308451688},{"file_id":"1Kn7eCFf2PD4fERNGVb3krx-1xRHGHpfF","timestamp":1715691476760},{"file_id":"126AKuKla1fkZfXj4cw5xGazNnLoV7J52","timestamp":1715003922072}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}